{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SystemVerilog coverage using Athena AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To run this demo:\n",
    "\n",
    "- Create yourself an AWS account - easy and free\n",
    "- Add an IAM user with S3 full permissions and Athena full permissions\n",
    "- Fill in the IAM user credentials below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_ACCESS_KEY_ID=AKIAIEHJKISLJ7ZQ47IA\n",
      "env: AWS_SECRET_ACCESS_KEY=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\n",
      "{\n",
      "    \"Buckets\": [\n",
      "        {\n",
      "            \"Name\": \"aws-athena-query-results-290745964271-us-east-2\",\n",
      "            \"CreationDate\": \"2018-05-30T09:30:30.000Z\"\n",
      "        },\n",
      "        {\n",
      "            \"Name\": \"aws-athena-query-results-290745964271-us-west-2\",\n",
      "            \"CreationDate\": \"2018-05-30T10:48:38.000Z\"\n",
      "        }\n",
      "    ],\n",
      "    \"Owner\": {\n",
      "        \"DisplayName\": \"avidan.efody\",\n",
      "        \"ID\": \"1320b784ba63f4bc0db4255ee95cb858af74f1e6a094a06a5a7d88c2fac0ef32\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%set_env AWS_ACCESS_KEY_ID your_access_key_here\n",
    "%set_env AWS_SECRET_ACCESS_KEY your_secret_access_key_here\n",
    "\n",
    "# let's test that your credentials are working correct\n",
    "! aws s3api list-buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The raw data:\n",
    "- transactions_log - is the log of the transactions on an interface\n",
    "- type_information - is the type of each field printed in the transaction_log\n",
    "\n",
    "This information is generated by the following example: https://www.edaplayground.com/x/2hJC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_log = \\\n",
    "\"\"\"# Time:    0, dir: RD, addr: 1490070710, burst: WRAP, len: 15, id:  3, lock: EXCLUSIVE,\n",
    "# Time:   26, dir: WR, addr:  165377426, burst: INCR, len:  0, id: 12, lock: NORMAL,\n",
    "# Time:   61, dir: WR, addr: 2328599037, burst: INCR, len:  8, id: 13, lock: NORMAL,\n",
    "# Time:  110, dir: RD, addr: 2328599037, burst: WRAP, len:  7, id:  5, lock: EXCLUSIVE,\n",
    "# Time:  133, dir: RD, addr:  165377426, burst: WRAP, len:  3, id:  7, lock: NORMAL,\n",
    "# Time:  181, dir: WR, addr: 1490070710, burst: WRAP, len:  6, id: 11, lock: EXCLUSIVE,\n",
    "# Time:  207, dir: RD, addr: 1490070710, burst: FIXED, len: 15, id:  5, lock: EXCLUSIVE,\n",
    "# Time:  231, dir: RD, addr: 1490070710, burst: INCR, len:  6, id:  2, lock: NORMAL,\n",
    "# Time:  252, dir: RD, addr:  165377426, burst: WRAP, len:  9, id:  0, lock: NORMAL,\n",
    "# Time:  290, dir: WR, addr: 2328599037, burst: FIXED, len: 10, id: 11, lock: NORMAL,\n",
    "# Time:  300, dir: WR, addr: 1490070710, burst: INCR, len:  7, id:  4, lock: EXCLUSIVE,\n",
    "# Time:  313, dir: WR, addr: 3668650794, burst: WRAP, len: 12, id:  8, lock: NORMAL,\n",
    "# Time:  358, dir: RD, addr: 3668650794, burst: INCR, len: 12, id:  7, lock: NORMAL,\n",
    "# Time:  403, dir: WR, addr: 3668650794, burst: WRAP, len: 10, id: 11, lock: NORMAL,\n",
    "# Time:  445, dir: RD, addr: 2328599037, burst: INCR, len:  9, id:  2, lock: EXCLUSIVE,\n",
    "\"\"\"\n",
    "\n",
    "type_information = \\\n",
    "\"\"\"# Transaction meta: dir: enum{RD=32'sd0,WR=32'sd1}axi_vip::dir_t, addr:          32, burst: enum{FIXED=32'sd0,INCR=32'sd1,WRAP=32'sd2}axi_vip::burst_t, len:           4, id:           4, lock: enum{NORMAL=32'sd0,EXCLUSIVE=32'sd1,LOCKED=32'sd2}axi_vip::lock_t\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data and upload "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some general purpose packages\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "import subprocess\n",
    "import time\n",
    "import pandas\n",
    "\n",
    "# python package for AWS access\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to S3\n",
    "\n",
    "- transactions.log - contains the transactions as shown above\n",
    "- types.json - contains the values for each enumeration used\n",
    "- columns.csv - contains information about the type of each column\n",
    "\n",
    "All these files will be uploaded to S3, and then turned into Athena tables. Note that they all have different formats that Athena can digest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.getcwd()\n",
    "\n",
    "transactions_filename = script_dir + \"/simple_tb/test1/axi_master_1/log/transactions.log\"\n",
    "columns_filename = script_dir + \"/simple_tb/test1/axi_master_1/columns/columns.csv\"\n",
    "types_filename = script_dir + \"/simple_tb/types_info/types.json\"\n",
    "\n",
    "for path in [transactions_filename, columns_filename, types_filename]:\n",
    "    os.makedirs(os.path.dirname(path)) \n",
    "\n",
    "transactions_file = open(transactions_filename, \"w\")\n",
    "columns_file = open(columns_filename, \"w\")\n",
    "types_file = open(types_filename, \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract type/column information\n",
    "\n",
    "Turn the \"type_information\" variable into:\n",
    "- A file that has all enum values nicely organized in rows, \n",
    "- Another file that maps column name (i.e. \"dir\") to type (i.e. \"dir_t\")\n",
    "- A variable that stores SQL column definitions (i.e. dir -> string, len -> smallint)\n",
    "\n",
    "Also write the transactions into a file without any processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_information = type_information.split(\"# Transaction meta: \",1)[1]\n",
    "columns_defs = \"\"\n",
    "\n",
    "for type in type_information.split(\", \"):\n",
    "    if re.match('.*enum', type):\n",
    "        match = re.match('([^:]*): enum\\{(.*)\\}([^,]*)', type)\n",
    "        if match:\n",
    "            column_name = match.group(1)\n",
    "            enum_type_name = match.group(3)\n",
    "            columns_defs = columns_defs + \"`\" + column_name + \"` string,\\n\" \n",
    "            columns_file.write(column_name + \",\" + enum_type_name + \",0\\n\")\n",
    "            for enum_key_value in match.group(2).split(','):\n",
    "                match = re.match('([^=]+)=.*([0-9]+)', enum_key_value)\n",
    "                if match:\n",
    "                    entry = {}\n",
    "                    entry['enum_type_name'] = enum_type_name\n",
    "                    entry['enum_string'] = match.group(1)\n",
    "                    entry['enum_int'] = match.group(2)\n",
    "                    types_file.write(json.dumps(entry) + \"\\n\")\n",
    "    else:\n",
    "        match = re.match('([^ ]+): *([0-9]+)$', type)\n",
    "        if match:\n",
    "            column_name = match.group(1)\n",
    "            width = match.group(2)\n",
    "            width_int = int(width)\n",
    "            columns_file.write(column_name + \",int,\" + width + \"\\n\")\n",
    "            if width_int <= 15:\n",
    "                columns_defs = columns_defs + \"`\" + column_name + \"` smallint,\\n\"\n",
    "            elif width_int <= 31:\n",
    "                columns_defs = columns_defs + \"`\" + column_name + \"` int,\\n\"\n",
    "            else:\n",
    "                columns_defs = columns_defs + \"`\" + column_name + \"` bigint,\\n\"\n",
    "\n",
    "        else:\n",
    "            print(\"error parsing meta data: int type: \" + type + \" doesn't have a width field\")\n",
    "\n",
    "transactions_file.write(transaction_log)\n",
    "\n",
    "transactions_file.close()\n",
    "columns_file.close()\n",
    "types_file.close()\n",
    "\n",
    "columns_defs = columns_defs[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_bucket: coverage-demo\n",
      "Completed 100 Bytes/2.0 KiB (219 Bytes/s) with 3 file(s) remaining\r",
      "upload: simple_tb/test1/axi_master_1/columns/columns.csv to s3://coverage-demo/simple_tb/test1/axi_master_1/columns/columns.csv\n",
      "Completed 100 Bytes/2.0 KiB (219 Bytes/s) with 2 file(s) remaining\r",
      "Completed 1.4 KiB/2.0 KiB (1.2 KiB/s) with 2 file(s) remaining    \r",
      "upload: simple_tb/test1/axi_master_1/log/transactions.log to s3://coverage-demo/simple_tb/test1/axi_master_1/log/transactions.log\n",
      "Completed 1.4 KiB/2.0 KiB (1.2 KiB/s) with 1 file(s) remaining\r",
      "Completed 2.0 KiB/2.0 KiB (1.7 KiB/s) with 1 file(s) remaining\r",
      "upload: simple_tb/types_info/types.json to s3://coverage-demo/simple_tb/types_info/types.json\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "aws s3 mb s3://coverage-demo/\n",
    "aws s3 sync simple_tb/ s3://coverage-demo/simple_tb --delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create database structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a blocking query function\n",
    "\n",
    "A thin wrapper around boto3 to run a query and wait for it to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query, database, s3_output):\n",
    "    client = boto3.client('athena')\n",
    "    if database:\n",
    "        response = client.start_query_execution(\n",
    "            QueryString=query,\n",
    "            QueryExecutionContext={\n",
    "                'Database': database\n",
    "            },\n",
    "            ResultConfiguration={\n",
    "                'OutputLocation': s3_output,\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        response = client.start_query_execution(\n",
    "            QueryString=query,\n",
    "            ResultConfiguration={\n",
    "                'OutputLocation': s3_output,\n",
    "            }\n",
    "        )\n",
    "    print('Execution ID: ' + response['QueryExecutionId'])\n",
    "\n",
    "    # wait for query to finish\n",
    "    while True:\n",
    "        execution = client.get_query_execution(QueryExecutionId=response['QueryExecutionId'])\n",
    "        if execution['QueryExecution']['Status']['State'] in ['SUCCEEDED', 'FAILED']:\n",
    "            print(execution['QueryExecution']['Status']['State'])\n",
    "            break\n",
    "        else:\n",
    "            print(execution['QueryExecution']['Status']['State'])\n",
    "            time.sleep(2) \n",
    "\n",
    "    response = client.get_query_results(QueryExecutionId=response['QueryExecutionId'])\n",
    "    if response['ResultSet']['Rows']:\n",
    "        row_num = 0;\n",
    "        for raw_row in response['ResultSet']['Rows']:\n",
    "            row = list()\n",
    "            for cell in raw_row['Data']:\n",
    "                row.append(list(cell.values())[0])\n",
    "            if row_num is 0:\n",
    "                df = pandas.DataFrame(columns=row)\n",
    "            else:\n",
    "                df.loc[row_num] = row\n",
    "            row_num += 1\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tables\n",
    "\n",
    "first clean the database, then recreate it all the tables in it. Note that they're created from the files uploaded to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE EXTERNAL TABLE coverage_demo.enums_info (\n",
      "    `enum_type_name` string,\n",
      "    `enum_string` string,\n",
      "    `enum_int` int\n",
      "     )\n",
      "     ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'\n",
      "     WITH SERDEPROPERTIES (\n",
      "         'serialization.format' = '1'\n",
      "     ) LOCATION 's3://coverage-demo//simple_tb/types_info/'\n",
      "     TBLPROPERTIES ('has_encrypted_data'='false');\n",
      "\n",
      "CREATE EXTERNAL TABLE coverage_demo.columns_info (\n",
      "    `column_name` string,\n",
      "    `column_type` string,\n",
      "    `column_width` int\n",
      "     )\n",
      "     ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
      "     WITH SERDEPROPERTIES (\n",
      "         'separatorChar' = ','\n",
      "     ) LOCATION 's3://coverage-demo/simple_tb/test1/axi_master_1/columns/'\n",
      "     TBLPROPERTIES ('has_encrypted_data'='false');\n",
      "\n",
      "CREATE EXTERNAL TABLE coverage_demo.axi_if1_transactions (\n",
      "    `time` bigint,\n",
      "    `dir` string,\n",
      "`addr` bigint,\n",
      "`burst` string,\n",
      "`len` smallint,\n",
      "`id` smallint,\n",
      "`lock` string\n",
      "     )\n",
      "     ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.RegexSerDe'\n",
      "     WITH SERDEPROPERTIES (  \n",
      "         'input.regex'='# Time: *([^ ^,]*), dir: *([^ ^,]*), addr: *([^ ^,]*), burst: *([^ ^,]*), len: *([^ ^,]*), id: *([^ ^,]*), lock: *([^ ^,]*),' \n",
      "     ) LOCATION 's3://coverage-demo/simple_tb/test1/axi_master_1/log/'\n",
      "     TBLPROPERTIES ('has_encrypted_data'='false');\n",
      "\n",
      "Execution ID: a20e3721-79bc-410e-aaf8-35f510faa0d4\n",
      "RUNNING\n",
      "SUCCEEDED\n",
      "Execution ID: ab3b57ff-dcae-45ac-b5c6-b43e49c66cf1\n",
      "RUNNING\n",
      "SUCCEEDED\n",
      "Execution ID: 4d2504d8-a475-4dc9-b451-ca419594468d\n",
      "RUNNING\n",
      "SUCCEEDED\n",
      "Execution ID: 74d113f1-23f6-420b-9c9a-03479e804581\n",
      "RUNNING\n",
      "SUCCEEDED\n",
      "Execution ID: 768f49e1-f8e4-4353-9b1b-9b849dde3050\n",
      "RUNNING\n",
      "SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "s3_base = 's3://coverage-demo/'\n",
    "s3_output = 's3://coverage-demo/results/'\n",
    "database = 'coverage_demo'\n",
    "        \n",
    "drop_db = \"DROP DATABASE IF EXISTS %s CASCADE;\" % (database)\n",
    "\n",
    "create_db = \"CREATE DATABASE %s;\" % (database)\n",
    "\n",
    "create_enum_tbl = \\\n",
    "    \"\"\"CREATE EXTERNAL TABLE %s.%s (\n",
    "    `enum_type_name` string,\n",
    "    `enum_string` string,\n",
    "    `enum_int` int\n",
    "     )\n",
    "     ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'\n",
    "     WITH SERDEPROPERTIES (\n",
    "         'serialization.format' = '1'\n",
    "     ) LOCATION '%s'\n",
    "     TBLPROPERTIES ('has_encrypted_data'='false');\"\"\" % ( database, \"enums_info\", s3_base + \"/simple_tb/types_info/\" )\n",
    "\n",
    "print(create_enum_tbl + \"\\n\")\n",
    "\n",
    "create_columns_tbl = \\\n",
    "    \"\"\"CREATE EXTERNAL TABLE %s.%s (\n",
    "    `column_name` string,\n",
    "    `column_type` string,\n",
    "    `column_width` int\n",
    "     )\n",
    "     ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "     WITH SERDEPROPERTIES (\n",
    "         'separatorChar' = ','\n",
    "     ) LOCATION '%s'\n",
    "     TBLPROPERTIES ('has_encrypted_data'='false');\"\"\" % ( database, \"columns_info\", s3_base + \"simple_tb/test1/axi_master_1/columns/\" )\n",
    "\n",
    "print(create_columns_tbl + \"\\n\")\n",
    "\n",
    "create_tr_tbl = \\\n",
    "    \"\"\"CREATE EXTERNAL TABLE %s.%s (\n",
    "    `time` bigint,\n",
    "    %s\n",
    "     )\n",
    "     ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.RegexSerDe'\n",
    "     WITH SERDEPROPERTIES (  \n",
    "         'input.regex'='# Time: *([^ ^,]*), dir: *([^ ^,]*), addr: *([^ ^,]*), burst: *([^ ^,]*), len: *([^ ^,]*), id: *([^ ^,]*), lock: *([^ ^,]*),' \n",
    "     ) LOCATION '%s'\n",
    "     TBLPROPERTIES ('has_encrypted_data'='false');\"\"\" % ( database, \"axi_if1_transactions\", columns_defs, s3_base + \"simple_tb/test1/axi_master_1/log/\" )\n",
    "\n",
    "print(create_tr_tbl + \"\\n\")\n",
    "\n",
    "for query in [drop_db, create_db]:\n",
    "    run_query(query, \"\", s3_output)\n",
    "\n",
    "for query in [create_enum_tbl, create_columns_tbl, create_tr_tbl]:\n",
    "    run_query(query, database, s3_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interrupted RMW query\n",
    "\n",
    "Looking for exclusive read-exclusive write pair with a write in between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution ID: a3a88376-af6e-4528-b12b-d084cc37f8b6\n",
      "RUNNING\n",
      "SUCCEEDED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addr</th>\n",
       "      <th>read_time</th>\n",
       "      <th>interrupted_at</th>\n",
       "      <th>write_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1490070710</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1490070710</td>\n",
       "      <td>207</td>\n",
       "      <td>290</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         addr read_time interrupted_at write_time\n",
       "1  1490070710         0             26        181\n",
       "2  1490070710       207            290        300"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interrupted_rmw = \"\"\"select first_tr.addr as addr, first_tr.time as read_time,  min(middle_tr.time) as interrupted_at, min(second_tr.time) as write_time\n",
    "from (\n",
    "    select row_number() over () as num, inner1.time, inner1.addr, inner1.dir, inner1.lock from\n",
    "        axi_if1_transactions inner1\n",
    "    where\n",
    "        inner1.dir = 'WR' or\n",
    "        inner1.lock = 'EXCLUSIVE'\n",
    "    order by inner1.addr, inner1.time\n",
    "    ) first_tr,\n",
    "    (\n",
    "    select row_number() over () as num, inner1.time, inner1.addr, inner1.dir, inner1.lock from\n",
    "        axi_if1_transactions inner1\n",
    "    where\n",
    "        inner1.dir = 'WR' or\n",
    "        inner1.lock = 'EXCLUSIVE'\n",
    "    order by inner1.addr, inner1.time\n",
    "    ) second_tr,\n",
    "    (\n",
    "    select row_number() over () as num, inner1.time, inner1.addr, inner1.dir, inner1.lock from\n",
    "        axi_if1_transactions inner1\n",
    "    where\n",
    "        inner1.dir = 'WR' or\n",
    "        inner1.lock = 'EXCLUSIVE'\n",
    "    order by inner1.addr, inner1.time\n",
    "    ) middle_tr\n",
    "where first_tr.addr = second_tr.addr and\n",
    "         second_tr.addr = first_tr.addr and\n",
    "     first_tr.lock = 'EXCLUSIVE' and\n",
    "     second_tr.lock = 'EXCLUSIVE' and\n",
    "     first_tr.dir = 'RD' and\n",
    "     second_tr.dir = 'WR' and\n",
    "     middle_tr.dir = 'WR' and\n",
    "     first_tr.num < middle_tr.num and\n",
    "     middle_tr.num < second_tr.num\n",
    "group by 1,2;\"\"\"\n",
    "\n",
    "for query in [interrupted_rmw]:\n",
    "    df = run_query(query, database, s3_output)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
